{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 PyTorch 中，`nn.ModuleDict()` 和 `nn.Parameter()` 都是常用的模块和参数管理工具。它们分别用于管理子模块（如层和模型组件）和可训练参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.ModuleDict()`\n",
    "\n",
    "`nn.ModuleDict()` 是 `torch.nn.Module` 的一个容器，用于存储子模块。与普通的 Python 字典不同，`ModuleDict` 是专门为 PyTorch 中的子模块设计的，它确保所有存储在其中的模块（如 `nn.Linear`, `nn.Conv2d` 等）都能自动注册为模型的一部分，并且能够参与训练（包括自动求导）。\n",
    "\n",
    "主要特点：\n",
    "* 可以通过键值对存储多个子模块，键通常是字符串类型（表示层的名称），值是一个 `nn.Module` 类型的对象（表示具体的层）。\n",
    "* `ModuleDict` 会将存储的子模块自动加入到模型的 `parameters()` 和 `modules()` 中，从而使它们能参与梯度计算和优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleModel(\n",
      "  (layers): ModuleDict(\n",
      "    (layer1): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (layer2): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (layer3): Linear(in_features=30, out_features=40, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        # 使用 ModuleDict 来存储多个子模块\n",
    "        self.layers = nn.ModuleDict({\n",
    "            'layer1': nn.Linear(10, 20),\n",
    "            'layer2': nn.Linear(20, 30),\n",
    "            'layer3': nn.Linear(30, 40)\n",
    "        })\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 可以通过 ModuleDict 访问各个子模块\n",
    "        x = self.layers['layer1'](x)\n",
    "        x = self.layers['layer2'](x)\n",
    "        x = self.layers['layer3'](x)\n",
    "        return x\n",
    "\n",
    "# 创建模型并打印\n",
    "model = SimpleModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上述代码中，`self.layers` 是一个 `nn.ModuleDict()`，其中包含了三个线性层 `layer1`, `layer2`, 和 `layer3`。在 `forward` 方法中，可以通过 `self.layers['layer1']` 等访问每个子模块。\n",
    "\n",
    "优点：\n",
    "自动注册参数：所有的子模块会被自动注册，PyTorch 可以跟踪它们。\n",
    "易于管理：它使得处理多个子模块（特别是当你有多个类似的层时）变得更加简洁和灵活。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Parameter()`\n",
    "`nn.Parameter()` 是一个用来表示可训练参数的类。它通常用于将一个张量（tensor）转变为模型的参数，使得它能够在反向传播时计算梯度，并被优化器更新。\n",
    "\n",
    "主要特点：\n",
    "它本质上是一个 `Tensor`，但是 `Parameter` 会被自动注册为模型的可训练参数。\n",
    "`Parameter` 对象会被自动加入到模型的 `parameters()` 方法返回的参数列表中，因此优化器会自动优化它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleModel()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        # 使用 Parameter 来创建一个可训练的参数\n",
    "        self.weight = nn.Parameter(torch.randn(10, 5))  # 一个 10x5 的权重矩阵\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.matmul(x, self.weight)  # 将输入与权重矩阵相乘\n",
    "\n",
    "# 创建模型并打印\n",
    "model = SimpleModel()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上面的代码中，`self.weight` 是一个 `nn.Parameter()`，它表示模型中的一个权重矩阵。该矩阵会自动成为模型的可训练参数，在训练过程中会被更新。\n",
    "\n",
    "优点：\n",
    "自动注册：通过 `nn.Parameter()` 创建的张量会被自动注册为模型的参数。\n",
    "梯度计算：`Parameter` 会被视为一个需要求导的张量，能够参与反向传播和梯度更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "区别总结：\n",
    "* `nn.ModuleDict()` 是一个容器，用来存储多个 `nn.Module` 子模块，它可以帮助管理多个子模块，并且将它们注册为模型的一部分。\n",
    "  * 例如，用于存储层、嵌入层、注意力层等。\n",
    "* nn.Parameter() 是一个特殊的张量，表示模型的可训练参数，它会自动被注册为模型的参数，并参与梯度计算。\n",
    "例如，用于表示模型的权重、偏置等需要训练的参数。\n",
    "示例结合：\n",
    "在之前的 `GraphMSE` 代码中，`nn.ModuleDict()` 用来存储每个元路径的 MLP 层，而 `nn.Parameter()` 用来表示每个节点类型的权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "self.type_weight[node_type] = nn.Parameter(torch.Tensor(input_dim, pre_embed_dim))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里，`self.type_weight[node_type]` 是一个 `nn.Parameter()`，它是一个可训练的权重矩阵。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
